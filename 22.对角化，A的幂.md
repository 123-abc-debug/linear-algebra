不同特征值 → 保证可对角化

重复特征值 → 可能可对角化，也可能不可对角化

可对角化取决于每个重复特征值对应的特征向量能否凑够线性无关的数量

有些重复特征值的矩阵可能只有少量特征向量（例如缺陷矩阵，Jordan 块） → 不可对角化

# 对角化到差分方程的计算
这里有使用到差分方程进行计算我就有点不理解了

这个看完gibert 的可大概明白了，就是把两个方程 转化成矩阵，感觉这个方法也是很常规的


2.1 对角化：
 所谓矩阵对角化，其实介绍的就是一种矩阵分解方式。根据我们上一节学习的
特征值与特征向量，如果 A 有 n 个线性无关的特征向量，那么可以将它们组成一
个可逆方阵，进而将矩阵分解：
假设 A 的 n 个线性无关的特征向量组成矩阵 S，有：
S = [𝑥1, 𝑥2, … 𝑥𝑛
]
构造：AS = A[𝑥1, 𝑥2, … 𝑥𝑛
]
由特征值定义：A[𝑥1, 𝑥2, … 𝑥𝑛
] = [𝜆𝑥1, 𝜆𝑥2, … 𝜆𝑥𝑛
]
写成矩阵乘法形式：= [𝑥1, 𝑥2, … 𝑥𝑛
] [
𝜆1 0
0 𝜆2
0 0
0 0
0 0
0 0
… 0
0 𝜆𝑛
]
将由特征值组成的此对角矩阵记为
： AS = S

由于 S 是可逆矩阵，左乘𝑆
−1： 𝑆
−1AS = 
或者写为：A = 𝐒 
𝑺
−𝟏 


感觉核心是这个相似对角化的推导证明


